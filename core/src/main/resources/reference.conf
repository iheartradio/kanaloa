kanaloa {

  #Default settings
  default-dispatcher {
    workTimeout = 1m

    # how often dispatcher makes adjustment accordingly
    updateInterval = 1s

    # When backend fails the work, the dispatcher can retry it for this many times.
    workRetry   = 0

    workerPool {

      # Starting number of workers
      startingPoolSize = 10

      # Minimum number of workers
      minPoolSize = 1

      # Maximum number of workers
      maxPoolSize = 400

      # check if worker pool is in a healthy state every such interval.
      healthCheckInterval = 5s

      # whether or not log failures when retrieving routee
      logRouteeRetrievalError = true

      # whether or not to shutdown the whole dispatcher when all workers died
      shutdownOnAllWorkerDeath = true

      # default timeout for shutingdown
      defaultShutdownTimeout = 30s
    }

    circuitBreaker {
      enabled = on

      # Open duration per timeout, e.g. if the value is 10s and
      # there are 3 consecutive timeouts, the circuit breaker will be open for 30 seconds
      # if afterwards it gets another timeout, it will be open for another 40 seconds
      openDurationBase = 10s

      # CircuitBreaker opens for a worker when it sees consecutive timeouts at or above this threshold
      timeoutCountThreshold = 3
    }

    # Only applicable for pushing dispatcher
    # Algorithm used is PIE (Proportional Integral controller Enhanced)
    # see https://www.ietf.org/mail-archive/web/iccrg/current/pdfB57AZSheOH.pdf
    backPressure {
      enabled = on

      # Roughly speaking it's the threshold above which backpressure will start to drop requests
      referenceDelay = 30s

      # The factor of which the dropping probably is effect by difference between estimated delay and
      # referenceDelay. E.g. if the estimated delay is 11 seconds, and the reference delay is 10 seconds,
      # the probability will increase by ((11 - 10) / 10) * 0.2 = 2%, this is will be applied every
      # updateInterval
      delayFactorBase = 0.2

      # The factor of which the dropping probably is effect by difference between estimated delay and
      # last delay. E.g. if the estimated delay is 11 seconds, the last delay is 12 seconds and
      # the reference delay is 10 seconds, then probability will decrease by
      # ((12 - 11) / 10) * 0.1 = 1%, this is will be applied every
      # updateInterval
      delayTrendFactorBase = 0.1

      # Duration of unregulated high volumn traffic allowed
      durationOfBurstAllowed = 30s

      # The weight of the latest metric over old metrics when collecting
      # performance metrics.
      # E.g. if the last processing speed is 10 messsages per millis
      # and if the new processing speed collected is 6 msgs per millis
      # Given a weight of 0.3, the metrics
      # representing pool size 5 will be 6 * 0.3 + 10 * 0.7, i.e. 8.8 messages per millis
      # Obviously, this number should be between 0 and 1.
      weightOfLatestMetric = 0.3
    }

    # It automatically adjust the size of work pool (and thus the concurrency)
    # to an optimal one that provides the highest throughput.
    # This autothrottle works best when you expect the concurrency to performance function
    # to be a convex function, with which you can find a global optimal by walking towards
    # a better concurrency. For example, a CPU bound service may have an optimal concurrency
    # tied to the CPU cores available. When your service is IO bound, the optimal concurrency is
    # bound to optimal number of concurrent connections to that IO service - e.g. a 4 node
    # Elasticsearch cluster may handle 4-8 concurrent requests at optimal speed.
    # The dispatchers keep track of throughput at each pool size and perform the following
    # three resizing operations (one at a time) periodically:
    # 1. Downsize if it hasn't seen all workers ever fully utilized for a period of time.
    # 2. Explore to a random nearby pool size to try and collect throughput metrics.
    # 3. Optimize to a nearby pool size with a better (than any other nearby sizes)
    #    throughput metrics.
    # When the pool is fully-utilized (i.e. all workers are busy), it randomly chooses
    # between exploring and optimizing. When the pool has not been fully-utilized for a period of
    # time, it will downsize the pool to the last seen max utilization multiplied by
    # a configurable ratio.
    #
    # By constantly exploring and optimizing, the resizer will eventually walk to the optimal
    # size and remain nearby.
    # When the optimal size changes it will start walking towards the new one.
    autothrottle {

      enabled = on

      # The probability of ramping down when all workers are busy
      # during exploration.
      chanceOfScalingDownWhenFull = 0.1

      # Interval between each pool size adjustment attempt
      # This interval must be at least as long as the update interval
      resizeInterval = ${kanaloa.default-dispatcher.updateInterval}

      # If the workers have not been fully utilized (i.e. all workers are busy) for such length,
      # the autothrottle will downsize the pool.
      downsizeAfterUnderUtilization = 72h

      # When optimizing, the autothrottler only considers the sizes adjacent to the
      # current size. This number indicates how many adjacent sizes to consider.
      numOfAdjacentSizesToConsiderDuringOptimization = 12

      # Duration exploration, the ratio between the largest step size and
      # current pool size. E.g. if the current pool size is 50, and the
      # explore-step-size is 0.1, the maximum pool size change during
      # exploration will be +- 5
      exploreStepSize = 0.1

      # When downsizing after a long streak of underutilization, the autothrottler
      # will downsize the pool to the highest utiliziation multiplied by a
      # a downsize ratio. This downsize ratio determines the new pool size
      # in comparison to the highest utilization.
      # E.g. if the highest utilization is 10, and the downsize ratio
      # is 0.8, the pool will be downsized to 8
      downsizeRatio = 0.8

      # Probability of doing an exploration v.s. optimization.
      explorationRatio = 0.4

      # The weight of the latest metric over old metrics when collecting
      # performance metrics.
      # E.g. if the last processing speed is 10 millis per message at pool
      # size 5, and if the new processing speed collected is 6 millis per
      # message at pool size 5. Given a weight of 0.3, the metrics
      # representing pool size 5 will be 6 * 0.3 + 10 * 0.7, i.e. 8.8 millis
      # Obviously, this number should be between 0 and 1.
      weightOfLatestMetric = 0.5
    }

    # Metrics report configuration
    metrics {
      enabled = off
      #  statsd {
      #     host = "localhost"
      #     namespace = "reactiveDispatchers"
      #
      #     #Everything below is optional
      #     port = 8125
      #     eventSampleRate = 0.25
      #     statusSampleRate = 1
      #  }
    }

  }

  # Your dispatchers config goes here
  dispatchers {

  # Here is an exaample
  #  example {
  #    workTimeout = 3s
  #    circuitBreaker {
  #      errorRateThreshold = 0.7
  #    }
  #  }

  }


}
